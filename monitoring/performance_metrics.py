#!/usr/bin/env python3
"""
–°–∏—Å—Ç–µ–º–∞ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

import time
import psutil
import sqlite3
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import asyncio
import httpx

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

class PerformanceMetrics:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def __init__(self):
        self.metrics_db = "monitoring/performance_metrics.db"
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–µ—Ç—Ä–∏–∫"""
        try:
            conn = sqlite3.connect(self.metrics_db)
            cursor = conn.cursor()
            
            # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS system_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    cpu_percent REAL,
                    memory_percent REAL,
                    disk_usage_percent REAL,
                    network_io_bytes INTEGER,
                    active_connections INTEGER
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫ API
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS api_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    endpoint TEXT NOT NULL,
                    response_time REAL,
                    status_code INTEGER,
                    request_count INTEGER
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS db_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    table_name TEXT NOT NULL,
                    row_count INTEGER,
                    size_bytes INTEGER,
                    query_time REAL
                )
            """)
            
            conn.commit()
            conn.close()
            logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î –º–µ—Ç—Ä–∏–∫: {e}")
    
    def get_system_metrics(self) -> Dict:
        """–°–±–æ—Ä —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        try:
            # CPU
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # Memory
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            # Disk
            disk = psutil.disk_usage('/')
            disk_usage_percent = (disk.used / disk.total) * 100
            
            # Network
            network = psutil.net_io_counters()
            network_io_bytes = network.bytes_sent + network.bytes_recv
            
            # Active connections (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
            active_connections = len(psutil.net_connections())
            
            return {
                'timestamp': datetime.now().isoformat(),
                'cpu_percent': cpu_percent,
                'memory_percent': memory_percent,
                'disk_usage_percent': disk_usage_percent,
                'network_io_bytes': network_io_bytes,
                'active_connections': active_connections
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫: {e}")
            return {}
    
    async def get_api_metrics(self) -> List[Dict]:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ API"""
        endpoints = [
            'http://localhost:8000/health',
            'http://localhost:8001/health',
            'http://localhost:8000/api/v1/signals',
            'http://localhost:8001/api/v1/predictions/model-info'
        ]
        
        metrics = []
        
        for endpoint in endpoints:
            try:
                start_time = time.time()
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(endpoint)
                    response_time = time.time() - start_time
                    
                    metrics.append({
                        'timestamp': datetime.now().isoformat(),
                        'endpoint': endpoint,
                        'response_time': response_time,
                        'status_code': response.status_code,
                        'request_count': 1
                    })
            except Exception as e:
                metrics.append({
                    'timestamp': datetime.now().isoformat(),
                    'endpoint': endpoint,
                    'response_time': None,
                    'status_code': None,
                    'request_count': 0,
                    'error': str(e)
                })
        
        return metrics
    
    def get_database_metrics(self) -> List[Dict]:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î
            conn = sqlite3.connect('backend/crypto_analytics.db')
            cursor = conn.cursor()
            
            metrics = []
            tables = ['users', 'channels', 'signals', 'subscriptions']
            
            for table in tables:
                try:
                    # –í—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞
                    start_time = time.time()
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    row_count = cursor.fetchone()[0]
                    query_time = time.time() - start_time
                    
                    # –†–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
                    cursor.execute(f"SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name='{table}'")
                    if cursor.fetchone()[0] > 0:
                        size_bytes = row_count * 100  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                    else:
                        size_bytes = 0
                    
                    metrics.append({
                        'timestamp': datetime.now().isoformat(),
                        'table_name': table,
                        'row_count': row_count,
                        'size_bytes': size_bytes,
                        'query_time': query_time
                    })
                    
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table}: {e}")
            
            conn.close()
            return metrics
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –ë–î: {e}")
            return []
    
    def save_metrics(self, system_metrics: Dict, api_metrics: List[Dict], db_metrics: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect(self.metrics_db)
            cursor = conn.cursor()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            if system_metrics:
                cursor.execute("""
                    INSERT INTO system_metrics 
                    (timestamp, cpu_percent, memory_percent, disk_usage_percent, network_io_bytes, active_connections)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    system_metrics['timestamp'],
                    system_metrics.get('cpu_percent'),
                    system_metrics.get('memory_percent'),
                    system_metrics.get('disk_usage_percent'),
                    system_metrics.get('network_io_bytes'),
                    system_metrics.get('active_connections')
                ))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º API –º–µ—Ç—Ä–∏–∫–∏
            for metric in api_metrics:
                cursor.execute("""
                    INSERT INTO api_metrics 
                    (timestamp, endpoint, response_time, status_code, request_count)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    metric['timestamp'],
                    metric['endpoint'],
                    metric.get('response_time'),
                    metric.get('status_code'),
                    metric.get('request_count', 1)
                ))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ë–î
            for metric in db_metrics:
                cursor.execute("""
                    INSERT INTO db_metrics 
                    (timestamp, table_name, row_count, size_bytes, query_time)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    metric['timestamp'],
                    metric['table_name'],
                    metric['row_count'],
                    metric['size_bytes'],
                    metric['query_time']
                ))
            
            conn.commit()
            conn.close()
            logger.info("–ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
    
    def get_metrics_summary(self, hours: int = 1) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –º–µ—Ç—Ä–∏–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤"""
        try:
            conn = sqlite3.connect(self.metrics_db)
            cursor = conn.cursor()
            
            # –í—Ä–µ–º—è N —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥
            cutoff_time = (datetime.now() - timedelta(hours=hours)).isoformat()
            
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            cursor.execute("""
                SELECT 
                    AVG(cpu_percent) as avg_cpu,
                    AVG(memory_percent) as avg_memory,
                    AVG(disk_usage_percent) as avg_disk,
                    MAX(cpu_percent) as max_cpu,
                    MAX(memory_percent) as max_memory
                FROM system_metrics 
                WHERE timestamp > ?
            """, (cutoff_time,))
            
            system_summary = cursor.fetchone()
            
            # API –º–µ—Ç—Ä–∏–∫–∏
            cursor.execute("""
                SELECT 
                    endpoint,
                    AVG(response_time) as avg_response_time,
                    COUNT(*) as total_requests,
                    SUM(CASE WHEN status_code = 200 THEN 1 ELSE 0 END) as successful_requests
                FROM api_metrics 
                WHERE timestamp > ?
                GROUP BY endpoint
            """, (cutoff_time,))
            
            api_summary = cursor.fetchall()
            
            # –ú–µ—Ç—Ä–∏–∫–∏ –ë–î
            cursor.execute("""
                SELECT 
                    table_name,
                    AVG(row_count) as avg_rows,
                    AVG(query_time) as avg_query_time,
                    MAX(row_count) as max_rows
                FROM db_metrics 
                WHERE timestamp > ?
                GROUP BY table_name
            """, (cutoff_time,))
            
            db_summary = cursor.fetchall()
            
            conn.close()
            
            return {
                'period_hours': hours,
                'system': {
                    'avg_cpu_percent': system_summary[0] if system_summary[0] else 0,
                    'avg_memory_percent': system_summary[1] if system_summary[1] else 0,
                    'avg_disk_percent': system_summary[2] if system_summary[2] else 0,
                    'max_cpu_percent': system_summary[3] if system_summary[3] else 0,
                    'max_memory_percent': system_summary[4] if system_summary[4] else 0
                },
                'api': [
                    {
                        'endpoint': row[0],
                        'avg_response_time': row[1] if row[1] else 0,
                        'total_requests': row[2],
                        'success_rate': (row[3] / row[2] * 100) if row[2] > 0 else 0
                    }
                    for row in api_summary
                ],
                'database': [
                    {
                        'table_name': row[0],
                        'avg_rows': row[1] if row[1] else 0,
                        'avg_query_time': row[2] if row[2] else 0,
                        'max_rows': row[3] if row[3] else 0
                    }
                    for row in db_summary
                ]
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–æ–¥–∫–∏ –º–µ—Ç—Ä–∏–∫: {e}")
            return {}

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫"""
    metrics_collector = PerformanceMetrics()
    
    logger.info("üìä –ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
    
    # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
    system_metrics = metrics_collector.get_system_metrics()
    api_metrics = await metrics_collector.get_api_metrics()
    db_metrics = metrics_collector.get_database_metrics()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics_collector.save_metrics(system_metrics, api_metrics, db_metrics)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–≤–æ–¥–∫—É
    summary = metrics_collector.get_metrics_summary(hours=1)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä –ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
    print("=" * 50)
    
    if system_metrics:
        print(f"üíª –°–ò–°–¢–ï–ú–ù–´–ï –ú–ï–¢–†–ò–ö–ò:")
        print(f"  CPU: {system_metrics.get('cpu_percent', 0):.1f}%")
        print(f"  –ü–∞–º—è—Ç—å: {system_metrics.get('memory_percent', 0):.1f}%")
        print(f"  –î–∏—Å–∫: {system_metrics.get('disk_usage_percent', 0):.1f}%")
        print(f"  –°–µ—Ç—å: {system_metrics.get('network_io_bytes', 0) / 1024 / 1024:.1f} MB")
        print(f"  –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {system_metrics.get('active_connections', 0)}")
    
    if api_metrics:
        print(f"\nüåê API –ú–ï–¢–†–ò–ö–ò:")
        for metric in api_metrics:
            endpoint = metric['endpoint'].split('/')[-1]
            status = "‚úÖ" if metric.get('status_code') == 200 else "‚ùå"
            response_time = metric.get('response_time', 0)
            print(f"  {status} {endpoint}: {response_time:.3f}—Å")
    
    if db_metrics:
        print(f"\nüóÑÔ∏è –ë–ê–ó–ê –î–ê–ù–ù–´–•:")
        for metric in db_metrics:
            print(f"  üìã {metric['table_name']}: {metric['row_count']} –∑–∞–ø–∏—Å–µ–π")
    
    print("=" * 50)
    
    return summary

if __name__ == "__main__":
    asyncio.run(main())
