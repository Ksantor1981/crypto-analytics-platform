"""
–í—ã—Å–æ–∫–æ—Ç–æ—á–Ω—ã–π OCR —Å–µ—Ä–≤–∏—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫—Ä–∏–ø—Ç–æ-—Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
–û—Å–Ω–æ–≤–∞–Ω –Ω–∞ –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ analyst_crypto
"""
import os
import re
import logging
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from datetime import datetime
import base64
import io

# OCR –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    import easyocr
    import cv2
    import numpy as np
    from PIL import Image, ImageEnhance, ImageFilter
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    logging.warning("OCR –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install easyocr opencv-python pillow")

# NLP –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
try:
    import spacy
    from spacy.matcher import Matcher
    NLP_AVAILABLE = True
except ImportError:
    NLP_AVAILABLE = False
    logging.warning("NLP –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install spacy")

from sqlalchemy.orm import Session
from ..models.signal import Signal, SignalDirection
from ..models.channel import Channel
from ..schemas.signal import SignalCreate
from ..core.config import get_settings

logger = logging.getLogger(__name__)

class AdvancedOCRService:
    """
    –í—ã—Å–æ–∫–æ—Ç–æ—á–Ω—ã–π OCR —Å–µ—Ä–≤–∏—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫—Ä–∏–ø—Ç–æ-—Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    """
    
    def __init__(self, db: Session):
        self.db = db
        self.settings = get_settings()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OCR
        self.reader = None
        self.nlp = None
        self.matcher = None
        
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏ –¥–ª—è OCR
        self.languages = ['en', 'ru']  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π –∏ —Ä—É—Å—Å–∫–∏–π
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
        self.signal_patterns = {
            'long': [
                r'(?i)(long|buy|bullish|moon|pump|üöÄ|üìà).*?(\w+usdt).*?(\d+\.?\d*).*?(\d+\.?\d*).*?(\d+\.?\d*)',
                r'(?i)(\w+usdt).*?(long|buy|bullish).*?(\d+\.?\d*).*?(\d+\.?\d*).*?(\d+\.?\d*)',
                r'(?i)–≤—Ö–æ–¥.*?(\w+usdt).*?(–ª–æ–Ω–≥|–ø–æ–∫—É–ø–∫–∞).*?(\d+\.?\d*).*?(\d+\.?\d*).*?(\d+\.?\d*)',
            ],
            'short': [
                r'(?i)(short|sell|bearish|dump|crash|üìâ|üîª).*?(\w+usdt).*?(\d+\.?\d*).*?(\d+\.?\d*).*?(\d+\.?\d*)',
                r'(?i)(\w+usdt).*?(short|sell|bearish).*?(\d+\.?\d*).*?(\d+\.?\d*).*?(\d+\.?\d*)',
                r'(?i)–≤—Ö–æ–¥.*?(\w+usdt).*?(—à–æ—Ä—Ç|–ø—Ä–æ–¥–∞–∂–∞).*?(\d+\.?\d*).*?(\d+\.?\d*).*?(\d+\.?\d*)',
            ]
        }
        
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ä—ã
        self.supported_pairs = [
            'BTC/USDT', 'ETH/USDT', 'BNB/USDT', 'ADA/USDT', 'SOL/USDT',
            'DOT/USDT', 'MATIC/USDT', 'AVAX/USDT', 'LINK/USDT', 'UNI/USDT',
            'SHIB/USDT', 'DOGE/USDT', 'PEPE/USDT', 'FLOKI/USDT', 'BONK/USDT',
            'WIF/USDT', 'BOME/USDT', 'MYRO/USDT', 'POPCAT/USDT', 'BOOK/USDT'
        ]
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._initialize_ocr()
        self._initialize_nlp()
        
    def _initialize_ocr(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OCR —Å –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª—å—é"""
        if not OCR_AVAILABLE:
            logger.error("OCR –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
            return
            
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EasyOCR —Å –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
            # –ï—Å–ª–∏ –µ—Å—Ç—å –≥–æ—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞, –∑–∞–≥—Ä—É–∂–∞–µ–º –µ—ë
            model_path = self._get_custom_model_path()
            
            if model_path and os.path.exists(model_path):
                logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å –∏–∑: {model_path}")
                self.reader = easyocr.Reader(
                    self.languages,
                    model_storage_directory=model_path,
                    download_enabled=False
                )
            else:
                logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å EasyOCR")
                self.reader = easyocr.Reader(
                    self.languages,
                    gpu=False,  # CPU –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    download_enabled=True
                )
                
            logger.info("OCR –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OCR: {e}")
            self.reader = None
    
    def _initialize_nlp(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è NLP –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"""
        if not NLP_AVAILABLE:
            logger.warning("NLP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ regex")
            return
            
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å spaCy
            model_name = 'en_core_web_sm'
            try:
                self.nlp = spacy.load(model_name)
            except OSError:
                logger.warning(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: python -m spacy download {model_name}")
                return
                
            # –°–æ–∑–¥–∞–µ–º matcher –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            self.matcher = Matcher(self.nlp.vocab)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫—Ä–∏–ø—Ç–æ-—Å–∏–≥–Ω–∞–ª–æ–≤
            patterns = [
                [{"LOWER": {"IN": ["long", "buy", "bullish", "moon", "pump"]}}],
                [{"LOWER": {"IN": ["short", "sell", "bearish", "dump", "crash"]}}],
                [{"LOWER": {"IN": ["btc", "eth", "bnb", "ada", "sol"]}}],
                [{"LOWER": {"IN": ["usdt", "usdc", "btc"]}}],
            ]
            
            for pattern in patterns:
                self.matcher.add("CRYPTO_SIGNAL", [pattern])
                
            logger.info("NLP –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ NLP: {e}")
            self.nlp = None
            self.matcher = None
    
    def _get_custom_model_path(self) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
        # –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏ –∫ –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        possible_paths = [
            "models/ocr_model",
            "assets/ocr_model", 
            "data/ocr_model",
            "../analyst_crypto/models/ocr_model",
            "../analyst_crypto/assets/ocr_model"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
                
        return None
    
    async def extract_signals_from_image(
        self, 
        image_data: bytes, 
        channel_id: int,
        message_id: str = None
    ) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –≤—ã—Å–æ—á–∞–π—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
        
        Args:
            image_data: –ë–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            channel_id: ID –∫–∞–Ω–∞–ª–∞
            message_id: ID —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        """
        if not self.reader:
            logger.error("OCR –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return []
            
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            processed_image = await self._preprocess_image(image_data)
            
            # OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            ocr_results = await self._perform_ocr(processed_image)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞
            signals = await self._extract_signals_from_text(ocr_results, channel_id, message_id)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
            validated_signals = await self._validate_extracted_signals(signals)
            
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(validated_signals)} —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return validated_signals
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return []
    
    async def _preprocess_image(self, image_data: bytes) -> np.ndarray:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è OCR —Ç–æ—á–Ω–æ—Å—Ç–∏"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –±–∞–π—Ç—ã –≤ PIL Image
            image = Image.open(io.BytesIO(image_data))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(1.5)
            
            # –£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏
            image = image.filter(ImageFilter.SHARPEN)
            
            # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            width, height = image.size
            if width < 800 or height < 600:
                scale_factor = max(800/width, 600/height)
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array
            image_array = np.array(image)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BGR –¥–ª—è OpenCV
            image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ OpenCV
            # –£–¥–∞–ª–µ–Ω–∏–µ —à—É–º–∞
            denoised = cv2.fastNlMeansDenoisingColored(image_bgr, None, 10, 10, 7, 21)
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            cl = clahe.apply(l)
            enhanced = cv2.merge((cl,a,b))
            enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
            
            return enhanced
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(io.BytesIO(image_data))
            return np.array(image)
    
    async def _perform_ocr(self, image: np.ndarray) -> List[Tuple[str, float]]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ OCR —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é"""
        try:
            # OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            results = self.reader.readtext(image)
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            filtered_results = []
            for (bbox, text, confidence) in results:
                # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 0.6
                if confidence > 0.6:
                    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
                    cleaned_text = self._clean_ocr_text(text)
                    if cleaned_text:
                        filtered_results.append((cleaned_text, confidence))
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            filtered_results.sort(key=lambda x: x[1], reverse=True)
            
            logger.info(f"OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–ª {len(filtered_results)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤")
            return filtered_results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return []
    
    def _clean_ocr_text(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç OCR –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
        if not text:
            return ""
            
        # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        text = re.sub(r'\s+', ' ', text.strip())
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–∞—Å—Ç—ã—Ö OCR –æ—à–∏–±–æ–∫
        corrections = {
            '0': 'O',  # –ù–æ–ª—å —á–∞—Å—Ç–æ –ø—É—Ç–∞—é—Ç —Å –±—É–∫–≤–æ–π O
            '1': 'l',  # –ï–¥–∏–Ω–∏—Ü–∞ —Å –±—É–∫–≤–æ–π l
            '5': 'S',  # –ü—è—Ç–µ—Ä–∫–∞ —Å –±—É–∫–≤–æ–π S
            '8': 'B',  # –í–æ—Å—å–º–µ—Ä–∫–∞ —Å –±—É–∫–≤–æ–π B
            '|': 'I',  # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è —á–µ—Ä—Ç–∞ —Å –±—É–∫–≤–æ–π I
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∫—Ä–∏–ø—Ç–æ-—Å–∏–º–≤–æ–ª–æ–≤
        for wrong, correct in corrections.items():
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫—Ä–∏–ø—Ç–æ-—Å–∏–º–≤–æ–ª
            if re.search(rf'\b\w*{wrong}\w*\b', text, re.IGNORECASE):
                text = re.sub(rf'\b(\w*){wrong}(\w*)\b', rf'\1{correct}\2', text, flags=re.IGNORECASE)
        
        return text
    
    async def _extract_signals_from_text(
        self, 
        ocr_results: List[Tuple[str, float]], 
        channel_id: int,
        message_id: str
    ) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        signals = []
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        full_text = " ".join([text for text, _ in ocr_results])
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é NLP –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if self.nlp and self.matcher:
            nlp_signals = await self._extract_signals_with_nlp(full_text, channel_id, message_id)
            signals.extend(nlp_signals)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        regex_signals = await self._extract_signals_with_regex(full_text, channel_id, message_id)
        signals.extend(regex_signals)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_signals = self._remove_duplicate_signals(signals)
        
        return unique_signals
    
    async def _extract_signals_with_nlp(
        self, 
        text: str, 
        channel_id: int,
        message_id: str
    ) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é NLP"""
        signals = []
        
        try:
            doc = self.nlp(text)
            matches = self.matcher(doc)
            
            for match_id, start, end in matches:
                span = doc[start:end]
                
                # –ò—â–µ–º —Ç–æ—Ä–≥–æ–≤—É—é –ø–∞—Ä—É —Ä—è–¥–æ–º —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
                pair = self._find_trading_pair_near_span(doc, start, end)
                if not pair:
                    continue
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                direction = self._determine_direction_from_span(span.text)
                if not direction:
                    continue
                
                # –ò—â–µ–º —Ü–µ–Ω—ã
                prices = self._extract_prices_from_context(doc, start, end)
                if len(prices) < 3:  # –ù—É–∂–Ω—ã entry, target, stop
                    continue
                
                signal = {
                    'trading_pair': pair,
                    'direction': direction,
                    'entry_price': prices[0],
                    'target_price': prices[1],
                    'stop_loss': prices[2],
                    'confidence': 0.8,  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è NLP
                    'source': 'ocr_nlp',
                    'channel_id': channel_id,
                    'message_id': message_id,
                    'extracted_at': datetime.utcnow()
                }
                
                signals.append(signal)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ NLP –∞–Ω–∞–ª–∏–∑–∞: {e}")
            
        return signals
    
    async def _extract_signals_with_regex(
        self, 
        text: str, 
        channel_id: int,
        message_id: str
    ) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        signals = []
        
        for direction, patterns in self.signal_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE)
                
                for match in matches:
                    try:
                        groups = match.groups()
                        
                        if len(groups) >= 5:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≥—Ä—É–ø–ø
                            action = groups[0].lower()
                            pair = groups[1].upper()
                            entry_price = float(groups[2])
                            target_price = float(groups[3])
                            stop_loss = float(groups[4])
                            
                            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–æ—Ä–≥–æ–≤—É—é –ø–∞—Ä—É
                            if not self._is_valid_trading_pair(pair):
                                continue
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                            signal_direction = self._determine_direction(action)
                            if not signal_direction:
                                continue
                            
                            signal = {
                                'trading_pair': pair,
                                'direction': signal_direction,
                                'entry_price': entry_price,
                                'target_price': target_price,
                                'stop_loss': stop_loss,
                                'confidence': 0.7,  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è regex
                                'source': 'ocr_regex',
                                'channel_id': channel_id,
                                'message_id': message_id,
                                'extracted_at': datetime.utcnow()
                            }
                            
                            signals.append(signal)
                            
                    except (ValueError, IndexError) as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ regex match: {e}")
                        continue
        
        return signals
    
    def _find_trading_pair_near_span(self, doc, start: int, end: int) -> Optional[str]:
        """–ü–æ–∏—Å–∫ —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã —Ä—è–¥–æ–º —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º"""
        # –ò—â–µ–º –≤ –æ–∫–Ω–µ ¬±5 —Ç–æ–∫–µ–Ω–æ–≤
        search_start = max(0, start - 5)
        search_end = min(len(doc), end + 5)
        
        for i in range(search_start, search_end):
            token = doc[i].text.upper()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–æ—Ä–≥–æ–≤—É—é –ø–∞—Ä—É
            if self._is_valid_trading_pair(token):
                return token
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é —Ç–æ–∫–µ–Ω–æ–≤
            if i < len(doc) - 1:
                combined = f"{token}/{doc[i+1].text.upper()}"
                if self._is_valid_trading_pair(combined):
                    return combined
        
        return None
    
    def _determine_direction_from_span(self, span_text: str) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–∑ span —Ç–µ–∫—Å—Ç–∞"""
        span_lower = span_text.lower()
        
        if any(word in span_lower for word in ['long', 'buy', 'bullish', 'moon', 'pump']):
            return 'LONG'
        elif any(word in span_lower for word in ['short', 'sell', 'bearish', 'dump', 'crash']):
            return 'SHORT'
            
        return None
    
    def _extract_prices_from_context(self, doc, start: int, end: int) -> List[float]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        prices = []
        
        # –ò—â–µ–º —á–∏—Å–ª–∞ –≤ –æ–∫–Ω–µ ¬±10 —Ç–æ–∫–µ–Ω–æ–≤
        search_start = max(0, start - 10)
        search_end = min(len(doc), end + 10)
        
        for i in range(search_start, search_end):
            token = doc[i].text
            
            # –ò—â–µ–º —á–∏—Å–ª–∞
            if re.match(r'^\d+\.?\d*$', token):
                try:
                    price = float(token)
                    if 0.000001 <= price <= 1000000:  # –†–∞–∑—É–º–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω
                        prices.append(price)
                except ValueError:
                    continue
        
        return sorted(prices)[:3]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —Ü–µ–Ω—ã
    
    def _is_valid_trading_pair(self, pair: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã"""
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–∞—Ä—É
        pair = pair.upper().replace('/', '')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–∞—Ä—ã
        for known_pair in self.supported_pairs:
            if pair in known_pair.replace('/', ''):
                return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –∫—Ä–∏–ø—Ç–æ/USDT
        if re.match(r'^[A-Z]{2,10}USDT$', pair):
            return True
            
        return False
    
    def _determine_direction(self, action: str) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞"""
        action_lower = action.lower()
        
        if any(word in action_lower for word in ['long', 'buy', 'bullish', 'moon', 'pump', '–ª–æ–Ω–≥', '–ø–æ–∫—É–ø–∫–∞']):
            return 'LONG'
        elif any(word in action_lower for word in ['short', 'sell', 'bearish', 'dump', 'crash', '—à–æ—Ä—Ç', '–ø—Ä–æ–¥–∞–∂–∞']):
            return 'SHORT'
            
        return None
    
    def _remove_duplicate_signals(self, signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        unique_signals = []
        seen = set()
        
        for signal in signals:
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            key = (
                signal['trading_pair'],
                signal['direction'],
                round(signal['entry_price'], 6),
                round(signal['target_price'], 6),
                round(signal['stop_loss'], 6)
            )
            
            if key not in seen:
                seen.add(key)
                unique_signals.append(signal)
        
        return unique_signals
    
    async def _validate_extracted_signals(self, signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤"""
        validated_signals = []
        
        for signal in signals:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                required_fields = ['trading_pair', 'direction', 'entry_price', 'target_price', 'stop_loss']
                if not all(field in signal for field in required_fields):
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ü–µ–Ω
                if not (0.000001 <= signal['entry_price'] <= 1000000):
                    continue
                if not (0.000001 <= signal['target_price'] <= 1000000):
                    continue
                if not (0.000001 <= signal['stop_loss'] <= 1000000):
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏–∫—É —Ü–µ–Ω
                if signal['direction'] == 'LONG':
                    if signal['target_price'] <= signal['entry_price']:
                        continue
                    if signal['stop_loss'] >= signal['entry_price']:
                        continue
                else:  # SHORT
                    if signal['target_price'] >= signal['entry_price']:
                        continue
                    if signal['stop_loss'] <= signal['entry_price']:
                        continue
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                signal['leverage'] = 1.0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                signal['risk_reward_ratio'] = abs(
                    (signal['target_price'] - signal['entry_price']) / 
                    (signal['entry_price'] - signal['stop_loss'])
                )
                
                validated_signals.append(signal)
                
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞: {e}")
                continue
        
        return validated_signals
    
    async def save_extracted_signals(self, signals: List[Dict[str, Any]]) -> List[Signal]:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        saved_signals = []
        
        for signal_data in signals:
            try:
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å–∏–≥–Ω–∞–ª–∞
                signal_create = SignalCreate(
                    trading_pair=signal_data['trading_pair'],
                    direction=SignalDirection.LONG if signal_data['direction'] == 'LONG' else SignalDirection.SHORT,
                    entry_price=signal_data['entry_price'],
                    target_price=signal_data['target_price'],
                    stop_loss=signal_data['stop_loss'],
                    leverage=signal_data.get('leverage', 1.0),
                    confidence=signal_data.get('confidence', 0.7),
                    source='ocr',
                    channel_id=signal_data['channel_id'],
                    message_id=signal_data.get('message_id'),
                    extracted_at=signal_data.get('extracted_at', datetime.utcnow())
                )
                
                # –°–æ–∑–¥–∞–µ–º —Å–∏–≥–Ω–∞–ª –≤ –±–∞–∑–µ
                signal = Signal(**signal_create.dict())
                self.db.add(signal)
                self.db.commit()
                self.db.refresh(signal)
                
                saved_signals.append(signal)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞: {e}")
                self.db.rollback()
                continue
        
        return saved_signals
    
    async def get_ocr_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ OCR —Ä–∞–±–æ—Ç—ã"""
        try:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
            total_signals = self.db.query(Signal).filter(Signal.source == 'ocr').count()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º
            channel_stats = self.db.query(
                Signal.channel_id,
                Channel.name,
                self.db.func.count(Signal.id).label('signal_count'),
                self.db.func.avg(Signal.confidence).label('avg_confidence')
            ).join(Channel).filter(
                Signal.source == 'ocr'
            ).group_by(Signal.channel_id, Channel.name).all()
            
            return {
                'total_ocr_signals': total_signals,
                'channel_statistics': [
                    {
                        'channel_id': stat.channel_id,
                        'channel_name': stat.name,
                        'signal_count': stat.signal_count,
                        'avg_confidence': float(stat.avg_confidence) if stat.avg_confidence else 0.0
                    }
                    for stat in channel_stats
                ],
                'ocr_available': OCR_AVAILABLE,
                'nlp_available': NLP_AVAILABLE,
                'model_loaded': self.reader is not None
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è OCR —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {
                'total_ocr_signals': 0,
                'channel_statistics': [],
                'ocr_available': OCR_AVAILABLE,
                'nlp_available': NLP_AVAILABLE,
                'model_loaded': self.reader is not None
            }
