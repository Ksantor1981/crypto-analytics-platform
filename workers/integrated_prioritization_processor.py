import json
import logging
import time
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass, asdict

from improved_signal_parser import ImprovedSignal, ImprovedSignalExtractor, SignalDirection, SignalQuality
from signal_prioritization_system import SignalPrioritizationSystem, PrioritizationResult, SignalPriority, SignalGroup
from simple_multi_platform_parser import SimpleMultiPlatformParser

logger = logging.getLogger(__name__)

@dataclass
class IntegratedPrioritizationResult:
    raw_signals: List[ImprovedSignal]
    enhanced_signals: List[ImprovedSignal]
    prioritized_signals: List[SignalPriority]
    signal_groups: List[SignalGroup]
    processing_stats: Dict[str, Any]
    recommendations: List[str]
    execution_time: float

class IntegratedPrioritizationProcessor:
    def __init__(self):
        self.multi_platform_parser = SimpleMultiPlatformParser()
        self.prioritization_system = SignalPrioritizationSystem()
        
        logger.info("–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def process_and_prioritize_signals(self, 
                                     telegram_channels: Optional[List[Dict]] = None,
                                     include_reddit: bool = True,
                                     include_tradingview: bool = True) -> IntegratedPrioritizationResult:
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        start_time = time.time()
        
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # –®–∞–≥ 1: –°–±–æ—Ä —Å–∏–≥–Ω–∞–ª–æ–≤ —Å–æ –≤—Å–µ—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º
        logger.info("–®–∞–≥ 1: –°–±–æ—Ä —Å–∏–≥–Ω–∞–ª–æ–≤ —Å–æ –≤—Å–µ—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º")
        raw_signals = self._collect_signals_from_all_platforms(
            telegram_channels, include_reddit, include_tradingview
        )
        
        if not raw_signals:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return self._create_empty_result(start_time)
        
        logger.info(f"–°–æ–±—Ä–∞–Ω–æ {len(raw_signals)} —Å—ã—Ä—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # –®–∞–≥ 2: –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        logger.info("–®–∞–≥ 2: –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤")
        enhanced_signals = self._enhance_signal_quality(raw_signals)
        logger.info(f"–£–ª—É—á—à–µ–Ω–æ {len(enhanced_signals)} —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # –®–∞–≥ 3: –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
        logger.info("–®–∞–≥ 3: –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤")
        prioritization_result = self.prioritization_system.prioritize_signals(enhanced_signals)
        logger.info(f"–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(prioritization_result.prioritized_signals)} —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # –®–∞–≥ 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        logger.info("–®–∞–≥ 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
        recommendations = self._generate_integrated_recommendations(
            raw_signals, enhanced_signals, prioritization_result
        )
        
        # –®–∞–≥ 5: –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        processing_stats = self._collect_processing_statistics(
            raw_signals, enhanced_signals, prioritization_result
        )
        
        execution_time = time.time() - start_time
        
        result = IntegratedPrioritizationResult(
            raw_signals=raw_signals,
            enhanced_signals=enhanced_signals,
            prioritized_signals=prioritization_result.prioritized_signals,
            signal_groups=prioritization_result.signal_groups,
            processing_stats=processing_stats,
            recommendations=recommendations,
            execution_time=execution_time
        )
        
        logger.info(f"–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        return result

    def _collect_signals_from_all_platforms(self, 
                                          telegram_channels: Optional[List[Dict]] = None,
                                          include_reddit: bool = True,
                                          include_tradingview: bool = True) -> List[ImprovedSignal]:
        """–°–±–æ—Ä —Å–∏–≥–Ω–∞–ª–æ–≤ —Å–æ –≤—Å–µ—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º"""
        all_signals = []
        
        try:
            # –°–±–æ—Ä —Å –º—É–ª—å—Ç–∏–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
            multi_platform_result = self.multi_platform_parser.parse_all_platforms(
                telegram_channels=telegram_channels,
                include_reddit=include_reddit,
                include_tradingview=include_tradingview
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for platform, signals in multi_platform_result.items():
                if isinstance(signals, list):
                    all_signals.extend(signals)
                elif isinstance(signals, dict) and 'signals' in signals:
                    all_signals.extend(signals['signals'])
            
            logger.info(f"–°–æ–±—Ä–∞–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º: {len(all_signals)}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º: {e}")
        
        return all_signals

    def _enhance_signal_quality(self, signals: List[ImprovedSignal]) -> List[ImprovedSignal]:
        """–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        enhanced_signals = []
        
        for signal in signals:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–∏–≥–Ω–∞–ª —Å–ª–æ–≤–∞—Ä–µ–º –∏–ª–∏ –æ–±—ä–µ–∫—Ç–æ–º
                if isinstance(signal, dict):
                    # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, —Å–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç ImprovedSignal
                    enhanced_signal = ImprovedSignal(
                        id=signal.get('id', 'unknown'),
                        asset=signal.get('asset', ''),
                        direction=SignalDirection(signal.get('direction', 'LONG')),
                        entry_price=signal.get('entry_price', 0.0),
                        target_price=signal.get('target_price', 0.0),
                        stop_loss=signal.get('stop_loss', 0.0),
                        leverage=signal.get('leverage', 1),
                        timeframe=signal.get('timeframe', '4H'),
                        signal_quality=SignalQuality(signal.get('signal_quality', 'MEDIUM')),
                        real_confidence=signal.get('real_confidence', 50.0),
                        calculated_confidence=signal.get('calculated_confidence', 50.0),
                        channel=signal.get('channel', ''),
                        message_id=signal.get('message_id', ''),
                        original_text=signal.get('original_text', ''),
                        cleaned_text=signal.get('cleaned_text', ''),
                        signal_type=signal.get('signal_type', 'structured'),
                        timestamp=signal.get('timestamp', datetime.now().isoformat()),
                        extraction_time=signal.get('extraction_time', datetime.now().isoformat()),
                        bybit_available=signal.get('bybit_available', False),
                        is_valid=signal.get('is_valid', True),
                        validation_errors=signal.get('validation_errors', []),
                        risk_reward_ratio=signal.get('risk_reward_ratio', 0.0),
                        potential_profit=signal.get('potential_profit', 0.0),
                        potential_loss=signal.get('potential_loss', 0.0)
                    )
                else:
                    # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ –æ–±—ä–µ–∫—Ç ImprovedSignal
                    enhanced_signal = signal
                
                # –ü—Ä–æ—Å—Ç–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ - –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                enhanced_signal.calculate_quality()
                enhanced_signal.calculate_confidence()
                enhanced_signal.calculate_risk_reward()
                
                enhanced_signals.append(enhanced_signal)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ —Å–∏–≥–Ω–∞–ª–∞: {e}")
                # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Å–∏–≥–Ω–∞–ª, –µ—Å–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
                if isinstance(signal, dict):
                    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –æ–±—ä–µ–∫—Ç –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                    try:
                        basic_signal = ImprovedSignal(
                            id=signal.get('id', 'unknown'),
                            asset=signal.get('asset', ''),
                            direction=SignalDirection(signal.get('direction', 'LONG')),
                            entry_price=signal.get('entry_price', 0.0),
                            target_price=signal.get('target_price', 0.0),
                            stop_loss=signal.get('stop_loss', 0.0),
                            leverage=signal.get('leverage', 1),
                            timeframe=signal.get('timeframe', '4H'),
                            signal_quality=SignalQuality(signal.get('signal_quality', 'MEDIUM')),
                            real_confidence=signal.get('real_confidence', 50.0),
                            calculated_confidence=signal.get('calculated_confidence', 50.0),
                            channel=signal.get('channel', ''),
                            message_id=signal.get('message_id', ''),
                            original_text=signal.get('original_text', ''),
                            cleaned_text=signal.get('cleaned_text', ''),
                            signal_type=signal.get('signal_type', 'structured'),
                            timestamp=signal.get('timestamp', datetime.now().isoformat()),
                            extraction_time=signal.get('extraction_time', datetime.now().isoformat()),
                            bybit_available=signal.get('bybit_available', False),
                            is_valid=signal.get('is_valid', True),
                            validation_errors=signal.get('validation_errors', []),
                            risk_reward_ratio=signal.get('risk_reward_ratio', 0.0),
                            potential_profit=signal.get('potential_profit', 0.0),
                            potential_loss=signal.get('potential_loss', 0.0)
                        )
                        enhanced_signals.append(basic_signal)
                    except Exception as e2:
                        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª: {e2}")
                else:
                    enhanced_signals.append(signal)
        
        return enhanced_signals

    def _generate_integrated_recommendations(self, 
                                           raw_signals: List[ImprovedSignal],
                                           enhanced_signals: List[ImprovedSignal],
                                           prioritization_result: PrioritizationResult) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏
        recommendations.extend(prioritization_result.recommendations_summary)
        
        # –ê–Ω–∞–ª–∏–∑ —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        quality_improvements = 0
        for raw, enhanced in zip(raw_signals, enhanced_signals):
            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏, —É—á–∏—Ç—ã–≤–∞—è –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
            def get_confidence(signal):
                if hasattr(signal, 'real_confidence'):
                    return signal.real_confidence
                elif isinstance(signal, dict):
                    return signal.get('real_confidence', 0)
                return 0
            
            raw_confidence = get_confidence(raw)
            enhanced_confidence = get_confidence(enhanced)
            
            if enhanced_confidence > raw_confidence:
                quality_improvements += 1
        
        if quality_improvements > 0:
            improvement_rate = quality_improvements / len(raw_signals) * 100
            recommendations.append(f"üìà –£–ª—É—á—à–µ–Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ {improvement_rate:.1f}% —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        source_counts = {}
        for signal in enhanced_signals:
            if hasattr(signal, 'channel'):
                source = signal.channel
            elif isinstance(signal, dict):
                source = signal.get('channel', 'Unknown')
            else:
                source = 'Unknown'
            source_counts[source] = source_counts.get(source, 0) + 1
        
        top_sources = sorted(source_counts.items(), key=lambda x: x[1], reverse=True)[:3]
        if top_sources:
            recommendations.append(f"üìä –¢–æ–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(f'{source} ({count})' for source, count in top_sources)}")
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ—Ä–µ–π–º–æ–≤
        timeframe_counts = {}
        for signal in enhanced_signals:
            if hasattr(signal, 'timeframe'):
                tf = signal.timeframe
            elif isinstance(signal, dict):
                tf = signal.get('timeframe', 'Unknown')
            else:
                tf = 'Unknown'
            timeframe_counts[tf] = timeframe_counts.get(tf, 0) + 1
        
        if timeframe_counts:
            dominant_tf = max(timeframe_counts.items(), key=lambda x: x[1])
            recommendations.append(f"‚è∞ –ü—Ä–µ–æ–±–ª–∞–¥–∞—é—â–∏–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {dominant_tf[0]} ({dominant_tf[1]} —Å–∏–≥–Ω–∞–ª–æ–≤)")
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–æ—Ä–≥–æ–≤–ª–µ
        if len(enhanced_signals) > 10:
            recommendations.append("üí° –ú–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥")
        elif len(enhanced_signals) < 3:
            recommendations.append("‚ö†Ô∏è –ú–∞–ª–æ —Å–∏–≥–Ω–∞–ª–æ–≤ - –¥–æ–∂–¥–∏—Ç–µ—Å—å –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞")
        
        return recommendations

    def _collect_processing_statistics(self, 
                                     raw_signals: List[ImprovedSignal],
                                     enhanced_signals: List[ImprovedSignal],
                                     prioritization_result: PrioritizationResult) -> Dict[str, Any]:
        """–°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        stats = {
            'raw_signals_count': len(raw_signals),
            'enhanced_signals_count': len(enhanced_signals),
            'prioritized_signals_count': len(prioritization_result.prioritized_signals),
            'duplicates_removed': prioritization_result.duplicates_removed,
            'signal_groups_count': len(prioritization_result.signal_groups),
            'priority_distribution': prioritization_result.priority_distribution,
            'processing_timestamp': datetime.now().isoformat()
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        source_stats = {}
        for signal in enhanced_signals:
            if hasattr(signal, 'channel'):
                source = signal.channel
            elif isinstance(signal, dict):
                source = signal.get('channel', 'Unknown')
            else:
                source = 'Unknown'
                
            if hasattr(signal, 'real_confidence'):
                confidence = signal.real_confidence
            elif isinstance(signal, dict):
                confidence = signal.get('real_confidence', 0)
            else:
                confidence = 0
                
            if source not in source_stats:
                source_stats[source] = {'count': 0, 'avg_confidence': 0, 'total_confidence': 0}
            source_stats[source]['count'] += 1
            source_stats[source]['total_confidence'] += confidence
        
        for source in source_stats:
            source_stats[source]['avg_confidence'] = (
                source_stats[source]['total_confidence'] / source_stats[source]['count']
            )
        
        stats['source_statistics'] = source_stats
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–∫—Ç–∏–≤–∞–º
        asset_stats = {}
        for signal in enhanced_signals:
            if hasattr(signal, 'asset'):
                asset = signal.asset
            elif isinstance(signal, dict):
                asset = signal.get('asset', 'Unknown')
            else:
                asset = 'Unknown'
                
            if hasattr(signal, 'direction'):
                direction = signal.direction
            elif isinstance(signal, dict):
                direction = signal.get('direction', 'UNKNOWN')
            else:
                direction = 'UNKNOWN'
                
            if asset not in asset_stats:
                asset_stats[asset] = {'count': 0, 'long_count': 0, 'short_count': 0}
            asset_stats[asset]['count'] += 1
            if direction == SignalDirection.LONG:
                asset_stats[asset]['long_count'] += 1
            else:
                asset_stats[asset]['short_count'] += 1
        
        stats['asset_statistics'] = asset_stats
        
        return stats

    def _create_empty_result(self, start_time: float) -> IntegratedPrioritizationResult:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        execution_time = time.time() - start_time
        
        return IntegratedPrioritizationResult(
            raw_signals=[],
            enhanced_signals=[],
            prioritized_signals=[],
            signal_groups=[],
            processing_stats={
                'raw_signals_count': 0,
                'enhanced_signals_count': 0,
                'prioritized_signals_count': 0,
                'duplicates_removed': 0,
                'signal_groups_count': 0,
                'priority_distribution': {},
                'processing_timestamp': datetime.now().isoformat()
            },
            recommendations=["–ù–µ—Ç —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"],
            execution_time=execution_time
        )

    def save_integrated_results(self, result: IntegratedPrioritizationResult, 
                              filename: str = "integrated_prioritization_results.json"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            serializable_result = {
                'raw_signals': [asdict(s) for s in result.raw_signals],
                'enhanced_signals': [asdict(s) for s in result.enhanced_signals],
                'prioritized_signals': [
                    {
                        'signal': asdict(p.signal),
                        'priority_score': p.priority_score,
                        'priority_level': p.priority_level.value,
                        'ranking_factors': p.ranking_factors,
                        'duplicate_info': p.duplicate_info,
                        'group_id': p.group_id,
                        'recommendations': p.recommendations
                    }
                    for p in result.prioritized_signals
                ],
                'signal_groups': [
                    {
                        'group_id': g.group_id,
                        'signals': [asdict(s) for s in g.signals],
                        'primary_signal': asdict(g.primary_signal),
                        'group_score': g.group_score,
                        'group_type': g.group_type,
                        'common_features': g.common_features,
                        'recommendations': g.recommendations
                    }
                    for g in result.signal_groups
                ],
                'processing_stats': result.processing_stats,
                'recommendations': result.recommendations,
                'execution_time': result.execution_time,
                'timestamp': datetime.now().isoformat()
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(serializable_result, f, indent=2, ensure_ascii=False)
            
            logger.info(f"–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

    def get_top_signals(self, result: IntegratedPrioritizationResult, 
                       limit: int = 10, 
                       priority_level: Optional[str] = None) -> List[SignalPriority]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø —Å–∏–≥–Ω–∞–ª–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
        signals = result.prioritized_signals
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—é –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        if priority_level:
            signals = [s for s in signals if s.priority_level.value == priority_level]
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
        signals.sort(key=lambda x: x.priority_score, reverse=True)
        return signals[:limit]

    def get_signal_groups_summary(self, result: IntegratedPrioritizationResult) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º —Å–∏–≥–Ω–∞–ª–æ–≤"""
        groups = result.signal_groups
        
        summary = {
            'total_groups': len(groups),
            'strong_consensus_groups': len([g for g in groups if g.group_type == "strong_consensus"]),
            'moderate_consensus_groups': len([g for g in groups if g.group_type == "moderate_consensus"]),
            'group_types_distribution': {},
            'top_groups': []
        }
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –≥—Ä—É–ø–ø
        group_types = [g.group_type for g in groups]
        for group_type in set(group_types):
            summary['group_types_distribution'][group_type] = group_types.count(group_type)
        
        # –¢–æ–ø –≥—Ä—É–ø–ø—ã –ø–æ —Å—á–µ—Ç—É
        top_groups = sorted(groups, key=lambda x: x.group_score, reverse=True)[:5]
        summary['top_groups'] = [
            {
                'group_id': g.group_id,
                'asset': g.common_features['asset'],
                'direction': g.common_features['direction'],
                'signal_count': g.common_features['signal_count'],
                'group_score': g.group_score,
                'group_type': g.group_type
            }
            for g in top_groups
        ]
        
        return summary

def main():
    """–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logging.basicConfig(level=logging.INFO)
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = IntegratedPrioritizationProcessor()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
    result = processor.process_and_prioritize_signals()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    processor.save_integrated_results(result)
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\n=== –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ ===")
    print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.execution_time:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"–°—ã—Ä—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {result.processing_stats['raw_signals_count']}")
    print(f"–£–ª—É—á—à–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {result.processing_stats['enhanced_signals_count']}")
    print(f"–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {result.processing_stats['prioritized_signals_count']}")
    print(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {result.processing_stats['duplicates_removed']}")
    print(f"–°–æ–∑–¥–∞–Ω–æ –≥—Ä—É–ø–ø: {result.processing_stats['signal_groups_count']}")
    
    print(f"\n=== –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ ===")
    for level, count in result.processing_stats['priority_distribution'].items():
        print(f"{level}: {count}")
    
    print(f"\n=== –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ ===")
    for rec in result.recommendations:
        print(f"‚Ä¢ {rec}")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø —Å–∏–≥–Ω–∞–ª—ã
    top_signals = processor.get_top_signals(result, limit=5)
    print(f"\n=== –¢–æ–ø 5 —Å–∏–≥–Ω–∞–ª–æ–≤ ===")
    for i, priority_signal in enumerate(top_signals):
        signal = priority_signal.signal
        print(f"{i+1}. {signal.asset} {signal.direction.value} @ {signal.entry_price}")
        print(f"   –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority_signal.priority_level.value} ({priority_signal.priority_score:.2f})")
        print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {signal.channel}")
        print()
    
    # –°–≤–æ–¥–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º
    groups_summary = processor.get_signal_groups_summary(result)
    print(f"\n=== –°–≤–æ–¥–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º ===")
    print(f"–í—Å–µ–≥–æ –≥—Ä—É–ø–ø: {groups_summary['total_groups']}")
    print(f"–°–∏–ª—å–Ω—ã–π –∫–æ–Ω—Å–µ–Ω—Å—É—Å: {groups_summary['strong_consensus_groups']}")
    print(f"–£–º–µ—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Å–µ–Ω—Å—É—Å: {groups_summary['moderate_consensus_groups']}")

if __name__ == "__main__":
    main()
