"""
Reddit Parser - –ü–∞—Ä—Å–µ—Ä –¥–ª—è Reddit –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ—Å—Ç–≤
–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫—É –∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö subreddit'–æ–≤
"""

import json
import logging
import time
import re
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
import requests
from improved_signal_parser import ImprovedSignal, ImprovedSignalExtractor, SignalDirection, SignalQuality

logger = logging.getLogger(__name__)

@dataclass
class RedditPost:
    """–ü–æ—Å—Ç —Å Reddit"""
    id: str
    title: str
    content: str
    author: str
    subreddit: str
    score: int
    comments_count: int
    created_utc: int
    url: str
    is_self: bool

@dataclass
class RedditComment:
    """–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å Reddit"""
    id: str
    body: str
    author: str
    score: int
    created_utc: int
    parent_id: str

class RedditParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è Reddit"""
    
    def __init__(self):
        self.extractor = ImprovedSignalExtractor()
        self.base_url = "https://www.reddit.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–µ subreddit'—ã
        self.subreddits = [
            'cryptocurrency',
            'bitcoin',
            'altcoin',
            'CryptoMoonShots',
            'CryptoCurrency',
            'CryptoMarkets',
            'CryptoNews',
            'CryptoTechnology'
        ]
        
        # –§–∏–ª—å—Ç—Ä—ã –¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        self.min_score = 10  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ—Å—Ç–∞
        self.min_comments = 5  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        self.max_age_hours = 24  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç –ø–æ—Å—Ç–∞ –≤ —á–∞—Å–∞—Ö
    
    def get_hot_posts(self, subreddit: str, limit: int = 25) -> List[RedditPost]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≥–æ—Ä—è—á–∏–µ –ø–æ—Å—Ç—ã –∏–∑ subreddit"""
        try:
            url = f"{self.base_url}/r/{subreddit}/hot.json?limit={limit}"
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            posts = []
            
            for post_data in data['data']['children']:
                post = post_data['data']
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                if (post['score'] >= self.min_score and 
                    post['num_comments'] >= self.min_comments and
                    not post['stickied'] and
                    not post['over_18']):
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç –ø–æ—Å—Ç–∞
                    post_age = time.time() - post['created_utc']
                    if post_age <= self.max_age_hours * 3600:
                        
                        reddit_post = RedditPost(
                            id=post['id'],
                            title=post['title'],
                            content=post.get('selftext', ''),
                            author=post['author'],
                            subreddit=post['subreddit'],
                            score=post['score'],
                            comments_count=post['num_comments'],
                            created_utc=post['created_utc'],
                            url=post['url'],
                            is_self=post['is_self']
                        )
                        posts.append(reddit_post)
            
            return posts
            
        except Exception as e:
            logger.error(f"Error fetching posts from r/{subreddit}: {e}")
            return []
    
    def get_post_comments(self, subreddit: str, post_id: str, limit: int = 50) -> List[RedditComment]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –ø–æ—Å—Ç—É"""
        try:
            url = f"{self.base_url}/r/{subreddit}/comments/{post_id}.json?limit={limit}"
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            comments = []
            
            if len(data) > 1:  # –ï—Å—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                comments_data = data[1]['data']['children']
                
                for comment_data in comments_data:
                    if comment_data['kind'] == 't1':  # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
                        comment = comment_data['data']
                        
                        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                        if comment['score'] >= 2 and len(comment['body']) > 20:
                            
                            reddit_comment = RedditComment(
                                id=comment['id'],
                                body=comment['body'],
                                author=comment['author'],
                                score=comment['score'],
                                created_utc=comment['created_utc'],
                                parent_id=comment['parent_id']
                            )
                            comments.append(reddit_comment)
            
            return comments
            
        except Exception as e:
            logger.error(f"Error fetching comments for post {post_id}: {e}")
            return []
    
    def extract_signals_from_text(self, text: str, source: str, source_id: str) -> List[ImprovedSignal]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç Reddit-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            cleaned_text = self._clean_reddit_text(text)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã
            signals = self.extractor.extract_signals_from_text(cleaned_text, source, source_id)
            
            # –û–±–æ–≥–∞—â–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
            for signal in signals:
                signal.channel = source
                signal.message_id = source_id
                signal.signal_type = "reddit"
            
            return signals
            
        except Exception as e:
            logger.error(f"Error extracting signals from text: {e}")
            return []
    
    def _clean_reddit_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç Reddit-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
        # –£–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ Reddit
        text = re.sub(r'https?://(?:www\.)?reddit\.com[^\s]*', '', text)
        
        # –£–±–∏—Ä–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        text = re.sub(r'/u/[^\s]+', '', text)
        text = re.sub(r'u/[^\s]+', '', text)
        
        # –£–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ subreddit'—ã
        text = re.sub(r'/r/[^\s]+', '', text)
        text = re.sub(r'r/[^\s]+', '', text)
        
        # –£–±–∏—Ä–∞–µ–º markdown —Ä–∞–∑–º–µ—Ç–∫—É
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # –ñ–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç
        text = re.sub(r'\*([^*]+)\*', r'\1', text)      # –ö—É—Ä—Å–∏–≤
        text = re.sub(r'`([^`]+)`', r'\1', text)        # –ö–æ–¥
        text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)  # –°—Å—ã–ª–∫–∏
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def analyze_post_relevance(self, post: RedditPost) -> float:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø–æ—Å—Ç–∞ –¥–ª—è –∫—Ä–∏–ø—Ç–æ-—Å–∏–≥–Ω–∞–ª–æ–≤"""
        relevance_score = 0.0
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫—Ä–∏–ø—Ç–æ-—Å–∏–≥–Ω–∞–ª–æ–≤
        crypto_keywords = [
            'buy', 'sell', 'long', 'short', 'entry', 'target', 'stop loss',
            'btc', 'eth', 'bitcoin', 'ethereum', 'altcoin', 'moon', 'pump',
            'dump', 'bullish', 'bearish', 'breakout', 'support', 'resistance',
            'technical analysis', 'ta', 'chart', 'price', 'market'
        ]
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        title_lower = post.title.lower()
        for keyword in crypto_keywords:
            if keyword in title_lower:
                relevance_score += 2.0
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
        content_lower = post.content.lower()
        for keyword in crypto_keywords:
            if keyword in content_lower:
                relevance_score += 1.0
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å
        relevance_score += min(post.score / 100, 5.0)  # –ú–∞–∫—Å–∏–º—É–º 5 –±–∞–ª–ª–æ–≤ –∑–∞ —Ä–µ–π—Ç–∏–Ω–≥
        relevance_score += min(post.comments_count / 20, 3.0)  # –ú–∞–∫—Å–∏–º—É–º 3 –±–∞–ª–ª–∞ –∑–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        
        return min(relevance_score, 20.0)  # –ú–∞–∫—Å–∏–º—É–º 20 –±–∞–ª–ª–æ–≤
    
    def parse_subreddit(self, subreddit: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç subreddit –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∏–≥–Ω–∞–ª—ã"""
        try:
            logger.info(f"Parsing subreddit: r/{subreddit}")
            
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ—Ä—è—á–∏–µ –ø–æ—Å—Ç—ã
            posts = self.get_hot_posts(subreddit)
            logger.info(f"Found {len(posts)} relevant posts in r/{subreddit}")
            
            all_signals = []
            processed_posts = 0
            
            for post in posts:
                try:
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                    relevance = self.analyze_post_relevance(post)
                    
                    if relevance >= 5.0:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                        title_signals = self.extract_signals_from_text(
                            post.title, f"reddit_{subreddit}", f"post_{post.id}_title"
                        )
                        
                        content_signals = self.extract_signals_from_text(
                            post.content, f"reddit_{subreddit}", f"post_{post.id}_content"
                        )
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –¥–ª—è —Ç–æ–ø-–ø–æ—Å—Ç–æ–≤
                        if post.score >= 50:
                            comments = self.get_post_comments(subreddit, post.id)
                            
                            for comment in comments[:10]:  # –¢–æ–ø-10 –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                                comment_signals = self.extract_signals_from_text(
                                    comment.body, f"reddit_{subreddit}", f"comment_{comment.id}"
                                )
                                all_signals.extend(comment_signals)
                        
                        all_signals.extend(title_signals)
                        all_signals.extend(content_signals)
                        processed_posts += 1
                        
                except Exception as e:
                    logger.error(f"Error processing post {post.id}: {e}")
                    continue
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ —Ä–∞–Ω–∂–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
            filtered_signals = self._filter_and_rank_signals(all_signals)
            
            return {
                'success': True,
                'subreddit': subreddit,
                'total_posts': len(posts),
                'processed_posts': processed_posts,
                'total_signals': len(all_signals),
                'filtered_signals': len(filtered_signals),
                'signals': filtered_signals,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error parsing subreddit r/{subreddit}: {e}")
            return {
                'success': False,
                'subreddit': subreddit,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _filter_and_rank_signals(self, signals: List[ImprovedSignal]) -> List[ImprovedSignal]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –∏ —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã"""
        if not signals:
            return []
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        filtered_signals = []
        for signal in signals:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–ª–µ–π
            if (signal.asset and 
                signal.direction and 
                (signal.entry_price or signal.target_price or signal.stop_loss)):
                filtered_signals.append(signal)
        
        # –†–∞–Ω–∂–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        filtered_signals.sort(key=lambda s: s.real_confidence or 0, reverse=True)
        
        return filtered_signals[:50]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-50 —Å–∏–≥–Ω–∞–ª–æ–≤
    
    def parse_all_subreddits(self) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ subreddit'—ã"""
        all_results = []
        total_signals = 0
        
        for subreddit in self.subreddits:
            try:
                result = self.parse_subreddit(subreddit)
                all_results.append(result)
                
                if result['success']:
                    total_signals += result['filtered_signals']
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(2)
                
            except Exception as e:
                logger.error(f"Error parsing subreddit {subreddit}: {e}")
                continue
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–∏–≥–Ω–∞–ª—ã
        all_signals = []
        for result in all_results:
            if result['success']:
                all_signals.extend(result['signals'])
        
        return {
            'success': True,
            'total_subreddits': len(self.subreddits),
            'successful_subreddits': len([r for r in all_results if r['success']]),
            'total_signals': total_signals,
            'all_signals': all_signals,
            'subreddit_results': all_results,
            'timestamp': datetime.now().isoformat()
        }

def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Reddit –ø–∞—Ä—Å–µ—Ä–∞"""
    parser = RedditParser()
    
    print("=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Reddit –ø–∞—Ä—Å–µ—Ä–∞ ===")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ subreddit
    print("\n1. –ü–∞—Ä—Å–∏–Ω–≥ r/cryptocurrency:")
    result = parser.parse_subreddit('cryptocurrency')
    
    if result['success']:
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {result['processed_posts']} –ø–æ—Å—Ç–æ–≤ –∏–∑ {result['total_posts']}")
        print(f"  –ù–∞–π–¥–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {result['total_signals']}")
        print(f"  –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {result['filtered_signals']}")
        
        if result['signals']:
            print(f"\nüìä –ü—Ä–∏–º–µ—Ä—ã —Å–∏–≥–Ω–∞–ª–æ–≤:")
            for signal in result['signals'][:3]:
                print(f"  - {signal.asset} {signal.direction.value}: {signal.signal_quality.value}")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö subreddit'–æ–≤
    print("\n2. –ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö subreddit'–æ–≤:")
    all_results = parser.parse_all_subreddits()
    
    if all_results['success']:
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {all_results['successful_subreddits']} subreddit'–æ–≤ –∏–∑ {all_results['total_subreddits']}")
        print(f"  –í—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {all_results['total_signals']}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        with open('reddit_signals.json', 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ reddit_signals.json")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤—Å–µ—Ö subreddit'–æ–≤")

if __name__ == "__main__":
    main()
