"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∞–ø–µ—Ä Telegram –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Å–±–æ—Ä–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
–†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ API, –∏—Å–ø–æ–ª—å–∑—É—è web scraping –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã
"""
import asyncio
import aiohttp
import re
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup
import json
import time
import random
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ sys.path
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from workers.real_data_config import TELEGRAM_API_ID, TELEGRAM_API_HASH
from workers.signal_patterns import SignalPatterns

logger = logging.getLogger(__name__)

class TelegramSignalScraper:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∞–ø–µ—Ä —Å–∏–≥–Ω–∞–ª–æ–≤ —Å Telegram –∫–∞–Ω–∞–ª–æ–≤
    –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –º–µ—Å—è—Ü–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API
    """
    
    def __init__(self):
        self.session = None
        self.signal_patterns = SignalPatterns()
        
        # –ö–∞–Ω–∞–ª—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.target_channels = [
            "signalsbitcoinandethereum",
            "cryptosignals",
            "bitcoin_signals",
            "crypto_signals_pro",
            "trading_signals_crypto",
            "cryptotrading_signals",
            "bitcoin_ethereum_signals",
            "crypto_signals_daily"
        ]
        
        # User agents –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36"
        ]
        
        # –ü—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.proxies = [
            # –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        ]
    
    async def start_session(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ HTTP —Å–µ—Å—Å–∏–∏"""
        if self.session is None:
            connector = aiohttp.TCPConnector(limit=10, limit_per_host=5)
            timeout = aiohttp.ClientTimeout(total=30)
            
            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers={
                    'User-Agent': random.choice(self.user_agents),
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive',
                }
            )
    
    async def close_session(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ HTTP —Å–µ—Å—Å–∏–∏"""
        if self.session:
            await self.session.close()
            self.session = None
    
    async def scrape_channel_messages(self, channel_username: str, months_back: int = 3) -> List[Dict[str, Any]]:
        """
        –°–∫—Ä–∞–ø–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∫–∞–Ω–∞–ª–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –º–µ—Å—è—Ü–µ–≤
        
        Args:
            channel_username: –ò–º—è –∫–∞–Ω–∞–ª–∞ –±–µ–∑ @
            months_back: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥ –¥–ª—è —Å–±–æ—Ä–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å —Å–∏–≥–Ω–∞–ª–∞–º–∏
        """
        await self.start_session()
        
        messages = []
        target_date = datetime.now() - timedelta(days=months_back * 30)
        
        try:
            # –ú–µ—Ç–æ–¥ 1: Telegram Web Scraping
            web_messages = await self._scrape_telegram_web(channel_username, target_date)
            messages.extend(web_messages)
            
            # –ú–µ—Ç–æ–¥ 2: Telegram Export Scraping
            export_messages = await self._scrape_telegram_export(channel_username, target_date)
            messages.extend(export_messages)
            
            # –ú–µ—Ç–æ–¥ 3: Alternative Sources
            alt_messages = await self._scrape_alternative_sources(channel_username, target_date)
            messages.extend(alt_messages)
            
            logger.info(f"–°–æ–±—Ä–∞–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∫–∞–Ω–∞–ª–∞ {channel_username}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞ {channel_username}: {e}")
        
        return messages
    
    async def _scrape_telegram_web(self, channel_username: str, target_date: datetime) -> List[Dict[str, Any]]:
        """–°–∫—Ä–∞–ø–∏–Ω–≥ —á–µ—Ä–µ–∑ Telegram Web"""
        messages = []
        
        try:
            # URL –¥–ª—è Telegram Web
            url = f"https://t.me/s/{channel_username}"
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # –ü–æ–∏—Å–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
                    message_elements = soup.find_all('div', class_='tgme_widget_message')
                    
                    for element in message_elements:
                        try:
                            message_data = await self._parse_telegram_message(element, channel_username)
                            if message_data and message_data['date'] >= target_date:
                                messages.append(message_data)
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                            continue
                            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ Telegram Web: {e}")
        
        return messages
    
    async def _scrape_telegram_export(self, channel_username: str, target_date: datetime) -> List[Dict[str, Any]]:
        """–°–∫—Ä–∞–ø–∏–Ω–≥ —á–µ—Ä–µ–∑ Telegram Export"""
        messages = []
        
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ export
            export_url = f"https://t.me/s/{channel_username}?before="
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü
            for page in range(1, 11):  # 10 —Å—Ç—Ä–∞–Ω–∏—Ü
                try:
                    url = f"{export_url}{page * 20}"
                    async with self.session.get(url) as response:
                        if response.status == 200:
                            html = await response.text()
                            soup = BeautifulSoup(html, 'html.parser')
                            
                            message_elements = soup.find_all('div', class_='tgme_widget_message')
                            
                            for element in message_elements:
                                try:
                                    message_data = await self._parse_telegram_message(element, channel_username)
                                    if message_data and message_data['date'] >= target_date:
                                        messages.append(message_data)
                                    elif message_data and message_data['date'] < target_date:
                                        # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ —Ü–µ–ª–µ–≤–æ–π –¥–∞—Ç—ã
                                        return messages
                                except Exception as e:
                                    continue
                    
                    # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    await asyncio.sleep(random.uniform(1, 3))
                    
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ Telegram Export: {e}")
        
        return messages
    
    async def _scrape_alternative_sources(self, channel_username: str, target_date: datetime) -> List[Dict[str, Any]]:
        """–°–∫—Ä–∞–ø–∏–Ω–≥ —á–µ—Ä–µ–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏"""
        messages = []
        
        try:
            # –ú–µ—Ç–æ–¥ 1: Telegram Archive Sites
            archive_urls = [
                f"https://telegram.me/s/{channel_username}",
                f"https://t.me/s/{channel_username}",
                f"https://telegram-store.com/channel/{channel_username}",
            ]
            
            for url in archive_urls:
                try:
                    async with self.session.get(url) as response:
                        if response.status == 200:
                            html = await response.text()
                            soup = BeautifulSoup(html, 'html.parser')
                            
                            # –ü–æ–∏—Å–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
                            message_elements = soup.find_all(['div', 'article'], class_=re.compile(r'message|post|entry'))
                            
                            for element in message_elements:
                                try:
                                    message_data = await self._parse_generic_message(element, channel_username)
                                    if message_data and message_data['date'] >= target_date:
                                        messages.append(message_data)
                                except Exception as e:
                                    continue
                    
                    await asyncio.sleep(random.uniform(2, 5))
                    
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {url}: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {e}")
        
        return messages
    
    async def _parse_telegram_message(self, element, channel_username: str) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram Web"""
        try:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            text_element = element.find('div', class_='tgme_widget_message_text')
            if not text_element:
                return None
            
            text = text_element.get_text(strip=True)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã
            date_element = element.find('time')
            if date_element:
                date_str = date_element.get('datetime', '')
                try:
                    date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                except:
                    date = datetime.now()
            else:
                date = datetime.now()
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID —Å–æ–æ–±—â–µ–Ω–∏—è
            message_id = element.get('data-post', '')
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            images = []
            img_elements = element.find_all('img')
            for img in img_elements:
                src = img.get('src', '')
                if src:
                    images.append(src)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏–≥–Ω–∞–ª
            if self._is_signal_message(text):
                return {
                    'channel_username': channel_username,
                    'message_id': message_id,
                    'text': text,
                    'date': date,
                    'images': images,
                    'source': 'telegram_web'
                }
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Telegram —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        
        return None
    
    async def _parse_generic_message(self, element, channel_username: str) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        try:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            text = element.get_text(strip=True)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã (–ø–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö)
            date = datetime.now()
            date_elements = element.find_all(['time', 'span', 'div'], class_=re.compile(r'date|time'))
            for date_elem in date_elements:
                try:
                    date_str = date_elem.get_text(strip=True)
                    # –ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞—Ç—ã
                    for fmt in ['%Y-%m-%d', '%d.%m.%Y', '%Y-%m-%d %H:%M:%S']:
                        try:
                            date = datetime.strptime(date_str, fmt)
                            break
                        except:
                            continue
                except:
                    continue
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            images = []
            img_elements = element.find_all('img')
            for img in img_elements:
                src = img.get('src', '')
                if src:
                    images.append(src)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏–≥–Ω–∞–ª
            if self._is_signal_message(text):
                return {
                    'channel_username': channel_username,
                    'message_id': f"alt_{hash(text)}",
                    'text': text,
                    'date': date,
                    'images': images,
                    'source': 'alternative'
                }
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ generic —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        
        return None
    
    def _is_signal_message(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–º"""
        if not text:
            return False
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤
        signal_keywords = [
            'long', 'short', 'buy', 'sell', 'entry', 'target', 'stop loss',
            'btc', 'eth', 'usdt', 'crypto', 'signal', 'trade',
            '–ª–æ–Ω–≥', '—à–æ—Ä—Ç', '–ø–æ–∫—É–ø–∫–∞', '–ø—Ä–æ–¥–∞–∂–∞', '–≤—Ö–æ–¥', '—Ü–µ–ª—å', '—Å—Ç–æ–ø',
            'üöÄ', 'üìà', 'üìâ', 'üí∞', 'üíé'
        ]
        
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        keyword_count = sum(1 for keyword in signal_keywords if keyword in text_lower)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ü–µ–Ω (—á–∏—Å–ª–∞ —Å —Ç–æ—á–∫–æ–π)
        price_pattern = r'\d+\.?\d*'
        prices = re.findall(price_pattern, text)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä
        pair_pattern = r'\b[A-Z]{2,10}/[A-Z]{2,10}\b'
        pairs = re.findall(pair_pattern, text.upper())
        
        # –°–æ–æ–±—â–µ–Ω–∏–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è —Å–∏–≥–Ω–∞–ª–æ–º –µ—Å–ª–∏:
        # 1. –ï—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ò
        # 2. –ï—Å—Ç—å —Ü–µ–Ω—ã –ò–õ–ò —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ä—ã
        return keyword_count >= 2 and (len(prices) >= 2 or len(pairs) >= 1)
    
    async def extract_signals_from_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        signals = []
        
        for message in messages:
            try:
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞
                text_signals = self.signal_patterns.extract_signals_from_text(
                    message['text'], 
                    message['channel_username'],
                    message['message_id']
                )
                signals.extend(text_signals)
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–µ—Å–ª–∏ –µ—Å—Ç—å OCR)
                if message.get('images'):
                    for img_url in message['images']:
                        try:
                            # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                            img_data = await self._download_image(img_url)
                            if img_data:
                                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å OCR –æ–±—Ä–∞–±–æ—Ç–∫—É
                                # ocr_signals = await ocr_service.extract_signals_from_image(img_data)
                                # signals.extend(ocr_signals)
                                pass
                        except Exception as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        
        return signals
    
    async def _download_image(self, url: str) -> Optional[bytes]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    return await response.read()
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {url}: {e}")
        
        return None
    
    async def scrape_all_channels(self, months_back: int = 3) -> Dict[str, List[Dict[str, Any]]]:
        """–°–∫—Ä–∞–ø–∏–Ω–≥ –≤—Å–µ—Ö —Ü–µ–ª–µ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤"""
        all_signals = {}
        
        for channel in self.target_channels:
            try:
                logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º —Å–∫—Ä–∞–ø–∏–Ω–≥ –∫–∞–Ω–∞–ª–∞: {channel}")
                
                # –°–∫—Ä–∞–ø–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏–π
                messages = await self.scrape_channel_messages(channel, months_back)
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤
                signals = await self.extract_signals_from_messages(messages)
                
                all_signals[channel] = signals
                
                logger.info(f"–ö–∞–Ω–∞–ª {channel}: —Å–æ–±—Ä–∞–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π, –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤")
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∫–∞–Ω–∞–ª–∞–º–∏
                await asyncio.sleep(random.uniform(5, 10))
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞ {channel}: {e}")
                all_signals[channel] = []
        
        await self.close_session()
        return all_signals

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def main():
    scraper = TelegramSignalScraper()
    
    # –°–∫—Ä–∞–ø–∏–Ω–≥ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –º–µ—Å—è—Ü–∞
    results = await scraper.scrape_all_channels(months_back=3)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    with open('scraped_signals.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"–°–æ–±—Ä–∞–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤:")
    for channel, signals in results.items():
        print(f"{channel}: {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤")

if __name__ == "__main__":
    asyncio.run(main())
