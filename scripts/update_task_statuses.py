#!/usr/bin/env python3
"""
–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –∑–∞–¥–∞—á –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Tuple

class TaskStatusUpdater:
    def __init__(self):
        self.root = Path.cwd()
        self.status_map = {
            'IMPL': '‚úÖ –ì–û–¢–û–í–û',
            'PARTIAL': 'üîÑ –ß–ê–°–¢–ò–ß–ù–û', 
            'TBD': '‚¨ú –ù–ï –ì–û–¢–û–í–û'
        }
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
        with open(self.root / 'project_analysis.json', 'r', encoding='utf-8') as f:
            self.analysis = json.load(f)
    
    def get_task_status(self, task_text: str) -> Tuple[str, str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        task_lower = task_text.lower()
        
        # Frontend –∑–∞–¥–∞—á–∏ (100% –≥–æ—Ç–æ–≤–æ)
        if any(keyword in task_lower for keyword in [
            'next.js', 'typescript', 'eslint', 'prettier', 'husky', 'tailwind',
            '–≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞', 'landing', 'shadcn', 'ui –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã'
        ]):
            return '‚úÖ', 'IMPL'
        
        if any(keyword in task_lower for keyword in [
            '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è', '–≤—Ö–æ–¥', 'auth', 'login', 'register'
        ]):
            if self.analysis['frontend']['—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤—Ö–æ–¥–∞'] and self.analysis['frontend']['—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏']:
                return '‚úÖ', 'IMPL'
            elif self.analysis['frontend']['—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤—Ö–æ–¥–∞'] or self.analysis['frontend']['—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏']:
                return 'üîÑ', 'PARTIAL'
            return '‚¨ú', 'TBD'
        
        if any(keyword in task_lower for keyword in [
            'dashboard', '–¥–∞—à–±–æ—Ä–¥', '–¥–µ–º–æ'
        ]):
            if self.analysis['frontend']['–¥–∞—à–±–æ—Ä–¥'] and self.analysis['frontend']['—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–µ–º–æ']:
                return '‚úÖ', 'IMPL'
            elif self.analysis['frontend']['–¥–∞—à–±–æ—Ä–¥'] or self.analysis['frontend']['—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–µ–º–æ']:
                return 'üîÑ', 'PARTIAL'
            return '‚¨ú', 'TBD'
        
        # Backend –∑–∞–¥–∞—á–∏ (50% –≥–æ—Ç–æ–≤–æ)
        if any(keyword in task_lower for keyword in [
            'fastapi', 'main.py', 'backend'
        ]):
            if self.analysis['backend']['fastapi –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ']:
                return '‚úÖ', 'IMPL'
            return '‚¨ú', 'TBD'
        
        if any(keyword in task_lower for keyword in [
            'auth endpoints', 'channels endpoints', 'signals endpoints', 'api'
        ]):
            if all([
                self.analysis['backend']['auth endpoints'],
                self.analysis['backend']['channels endpoints'],
                self.analysis['backend']['signals endpoints']
            ]):
                return '‚úÖ', 'IMPL'
            elif any([
                self.analysis['backend']['auth endpoints'],
                self.analysis['backend']['channels endpoints'],
                self.analysis['backend']['signals endpoints']
            ]):
                return 'üîÑ', 'PARTIAL'
            return '‚¨ú', 'TBD'
        
        if any(keyword in task_lower for keyword in [
            '–º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö', '–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö', 'alembic', '–º–∏–≥—Ä–∞—Ü–∏–∏'
        ]):
            if self.analysis['backend']['–º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö'] and self.analysis['backend']['–º–∏–≥—Ä–∞—Ü–∏–∏ alembic']:
                return '‚úÖ', 'IMPL'
            elif self.analysis['backend']['–º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö'] or self.analysis['backend']['–º–∏–≥—Ä–∞—Ü–∏–∏ alembic']:
                return 'üîÑ', 'PARTIAL'
            return '‚¨ú', 'TBD'
        
        # ML Service –∑–∞–¥–∞—á–∏ (100% –≥–æ—Ç–æ–≤–æ)
        if any(keyword in task_lower for keyword in [
            'ml', 'machine learning', '–º–æ–¥–µ–ª–∏ ml', 'ml —Å–µ—Ä–≤–∏—Å'
        ]):
            if self.analysis['ml_service']['ml —Å–µ—Ä–≤–∏—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç']:
                return '‚úÖ', 'IMPL'
            return '‚¨ú', 'TBD'
        
        # Workers –∑–∞–¥–∞—á–∏ (75% –≥–æ—Ç–æ–≤–æ)
        if any(keyword in task_lower for keyword in [
            'celery', 'workers', 'tasks'
        ]):
            if self.analysis['workers']['celery –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è'] and self.analysis['workers']['tasks']:
                return '‚úÖ', 'IMPL'
            elif self.analysis['workers']['tasks']:
                return 'üîÑ', 'PARTIAL'
            return '‚¨ú', 'TBD'
        
        # Docker –∑–∞–¥–∞—á–∏ (75% –≥–æ—Ç–æ–≤–æ)
        if any(keyword in task_lower for keyword in [
            'docker', 'docker-compose'
        ]):
            if self.analysis['docker']['docker-compose.yml'] and self.analysis['docker']['docker-compose.override.yml']:
                return '‚úÖ', 'IMPL'
            elif self.analysis['docker']['docker-compose.yml']:
                return 'üîÑ', 'PARTIAL'
            return '‚¨ú', 'TBD'
        
        # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (75% –≥–æ—Ç–æ–≤–æ)
        if any(keyword in task_lower for keyword in [
            '–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è', 'api –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è', 'readme'
        ]):
            if self.analysis['documentation']['API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è']:
                return '‚úÖ', 'IMPL'
            elif self.analysis['documentation']['README.md']:
                return 'üîÑ', 'PARTIAL'
            return '‚¨ú', 'TBD'
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return '‚¨ú', 'TBD'
    
    def update_tasks_file(self, input_file: str, output_file: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –∑–∞–¥–∞—á–∞–º–∏"""
        input_path = self.root / input_file
        if not input_path.exists():
            print(f"–§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        lines = input_path.read_text(encoding='utf-8').splitlines()
        updated_lines = []
        
        for line in lines:
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –∑–∞–¥–∞—á–∞–º–∏
            task_match = re.match(r'^-\s*(‚úÖ|‚¨ú|üîÑ)\s*\[(IMPL|PARTIAL|TBD)\]\s*(.+)$', line)
            if task_match:
                mark, tag, task_text = task_match.groups()
                new_mark, new_tag = self.get_task_status(task_text)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                updated_line = f"- {new_mark} [{new_tag}] {task_text}"
                updated_lines.append(updated_line)
            else:
                updated_lines.append(line)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        output_path = self.root / output_file
        output_path.write_text('\n'.join(updated_lines), encoding='utf-8')
        
        print(f"–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        return True
    
    def generate_summary(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–∫–∏ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º"""
        summary = []
        summary.append('# –°–í–û–î–ö–ê –ü–û –°–¢–ê–¢–£–°–ê–ú –ó–ê–î–ê–ß')
        summary.append('')
        summary.append('## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞')
        summary.append('')
        
        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats = {'IMPL': 0, 'PARTIAL': 0, 'TBD': 0}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª –∑–∞–¥–∞—á
        tasks_file = self.root / 'TASKS2_ARCHIVE_DEDUPED_STATUS.md'
        if tasks_file.exists():
            content = tasks_file.read_text(encoding='utf-8')
            for line in content.splitlines():
                match = re.match(r'^-\s*(‚úÖ|‚¨ú|üîÑ)\s*\[(IMPL|PARTIAL|TBD)\]\s*(.+)$', line)
                if match:
                    tag = match.group(2)
                    stats[tag] += 1
        
        total = sum(stats.values())
        if total > 0:
            summary.append(f'- **–í—Å–µ–≥–æ –∑–∞–¥–∞—á:** {total}')
            summary.append(f'- **‚úÖ –ì–û–¢–û–í–û:** {stats["IMPL"]} ({stats["IMPL"]/total*100:.1f}%)')
            summary.append(f'- **üîÑ –ß–ê–°–¢–ò–ß–ù–û:** {stats["PARTIAL"]} ({stats["PARTIAL"]/total*100:.1f}%)')
            summary.append(f'- **‚¨ú –ù–ï –ì–û–¢–û–í–û:** {stats["TBD"]} ({stats["TBD"]/total*100:.1f}%)')
        
        summary.append('')
        summary.append('## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º')
        summary.append('')
        summary.append('### üî• –ö–†–ò–¢–ò–ß–ù–û (—Å–¥–µ–ª–∞—Ç—å –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å):')
        summary.append('- Backend API endpoints (auth, channels, signals)')
        summary.append('- Celery –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è workers')
        summary.append('- API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è')
        summary.append('')
        summary.append('### ‚ö° –í–ê–ñ–ù–û (—Å–¥–µ–ª–∞—Ç—å –≤–æ –≤—Ç–æ—Ä—É—é –æ—á–µ—Ä–µ–¥—å):')
        summary.append('- Docker-compose.override.yml')
        summary.append('- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã frontend')
        summary.append('- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã')
        summary.append('')
        summary.append('### üìù –ñ–ï–õ–ê–¢–ï–õ–¨–ù–û (—Å–¥–µ–ª–∞—Ç—å –≤ —Ç—Ä–µ—Ç—å—é –æ—á–µ—Ä–µ–¥—å):')
        summary.append('- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è')
        summary.append('- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ')
        summary.append('- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏')
        
        return '\n'.join(summary)

def main():
    updater = TaskStatusUpdater()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å—ã –≤ —Ñ–∞–π–ª–µ –∑–∞–¥–∞—á
    success = updater.update_tasks_file(
        'TASKS2_ARCHIVE_DEDUPED_STATUS.md',
        'TASKS2_UPDATED_STATUS.md'
    )
    
    if success:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–≤–æ–¥–∫—É
        summary = updater.generate_summary()
        summary_path = Path.cwd() / 'TASK_STATUS_SUMMARY.md'
        summary_path.write_text(summary, encoding='utf-8')
        
        print("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìÑ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏: TASKS2_UPDATED_STATUS.md")
        print(f"üìä –°–≤–æ–¥–∫–∞: TASK_STATUS_SUMMARY.md")
    
    return 0

if __name__ == '__main__':
    exit(main())
